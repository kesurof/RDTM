#!/usr/bin/env python3

import os
import time
import logging
import subprocess
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

from config import CURRENT_USER
from database import get_database

logger = logging.getLogger(__name__)

class FailureHandler:
    """Gestionnaire post-√©chec pour infringing_file et too_many_requests"""
    
    def __init__(self, dry_run: bool = True):
        self.dry_run = dry_run
        self.database = get_database()
        self.session = self._create_session()
        
        # Configuration des serveurs m√©dia (depuis advanced_symlink_checker)
        self.media_config = {
            'sonarr': {'port': 8989, 'api_version': 'v3'},
            'radarr': {'port': 7878, 'api_version': 'v3'}
        }
        
        logger.info(f"FailureHandler initialis√© (mode: {'DRY-RUN' if dry_run else 'R√âEL'})")
    
    def _create_session(self) -> requests.Session:
        """Cr√©e une session HTTP avec retry automatique"""
        session = requests.Session()
        retry_strategy = Retry(total=3, backoff_factor=1, status_forcelist=[429, 500, 502, 503, 504])
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        return session
    
    def handle_failure(self, torrent_id: str, filename: str, error_type: str, error_message: str) -> bool:
        """Point d'entr√©e principal pour g√©rer les √©checs"""
        logger.info(f"üîß Traitement √©chec {error_type} pour: {filename[:50]}...")
        
        if error_type == 'infringing_file':
            return self._handle_infringing_file(torrent_id, filename, error_message)
        elif error_type == 'too_many_requests':
            return self._handle_rate_limit(torrent_id, filename, error_message)
        else:
            logger.warning(f"Type d'erreur non g√©r√©: {error_type}")
            return False
    
    def _handle_infringing_file(self, torrent_id: str, filename: str, error_message: str) -> bool:
        """Gestion des fichiers censur√©s - suppression + scan Sonarr/Radarr"""
        logger.info(f"üìõ Traitement infringing_file: {filename[:50]}")
        
        try:
            # 1. Historiser l'√©chec d√©finitif
            self._record_permanent_failure(torrent_id, filename, 'infringing_file', error_message)
            
            # 2. Trouver et supprimer les liens cass√©s
            deleted_files = self._find_and_delete_broken_symlinks(filename)
            
            # 3. D√©clencher scan Sonarr/Radarr si des fichiers supprim√©s
            if deleted_files:
                self._trigger_media_rescan()
                logger.info(f"‚úÖ infringing_file trait√©: {len(deleted_files)} fichiers supprim√©s")
                return True
            else:
                logger.warning(f"‚ö†Ô∏è Aucun fichier trouv√© pour: {filename[:50]}")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Erreur traitement infringing_file {torrent_id}: {e}")
            return False
    
    def _handle_rate_limit(self, torrent_id: str, filename: str, error_message: str) -> bool:
        """Gestion rate limit - historisation pour retry dans 3h"""
        logger.info(f"‚è∞ Programmation retry pour: {filename[:50]}")
        
        try:
            # Calculer le moment du retry (dans 3h)
            retry_time = datetime.now() + timedelta(hours=3)
            
            # Enregistrer pour retry diff√©r√©
            self._schedule_retry(torrent_id, filename, 'too_many_requests', retry_time, error_message)
            
            logger.info(f"‚úÖ Retry programm√© pour {retry_time.strftime('%H:%M:%S')}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur programmation retry {torrent_id}: {e}")
            return False
    
    def _find_and_delete_broken_symlinks(self, filename: str) -> List[str]:
        """Trouve et supprime les liens cass√©s pour un fichier donn√©"""
        deleted_files = []
        base_path = f"/home/{CURRENT_USER}/Medias"
        
        if not os.path.exists(base_path):
            logger.warning(f"Chemin m√©dia inexistant: {base_path}")
            return []
        
        # Nettoyer le nom de fichier pour la recherche
        clean_filename = self._clean_filename_for_search(filename)
        
        logger.info(f"üîç Recherche liens cass√©s pour: {clean_filename}")
        
        try:
            # Parcourir tous les liens symboliques
            for root, dirs, files in os.walk(base_path):
                for file in files:
                    full_path = os.path.join(root, file)
                    
                    # V√©rifier si c'est un lien symbolique
                    if os.path.islink(full_path):
                        # V√©rifier si le nom correspond
                        if self._filename_matches(file, clean_filename):
                            # V√©rifier si le lien est cass√©
                            if not os.path.exists(full_path):
                                if self._delete_symlink(full_path):
                                    deleted_files.append(full_path)
                                    logger.info(f"üóëÔ∏è Supprim√©: {full_path}")
        
        except Exception as e:
            logger.error(f"Erreur recherche liens cass√©s: {e}")
        
        return deleted_files
    
    def _clean_filename_for_search(self, filename: str) -> str:
        """Nettoie le nom de fichier pour la recherche"""
        import re
        # Supprimer l'extension et nettoyer
        clean = os.path.splitext(filename)[0]
        clean = re.sub(r'[._-]', ' ', clean.lower())
        clean = ' '.join(clean.split())
        return clean
    
    def _filename_matches(self, link_name: str, target_name: str) -> bool:
        """V√©rifie si un nom de lien correspond au fichier cible"""
        from difflib import SequenceMatcher
        
        link_clean = self._clean_filename_for_search(link_name)
        similarity = SequenceMatcher(None, link_clean, target_name).ratio()
        
        # Seuil de similarit√© pour consid√©rer une correspondance
        return similarity > 0.8
    
    def _delete_symlink(self, file_path: str) -> bool:
        """Supprime un lien symbolique"""
        try:
            if self.dry_run:
                logger.info(f"[DRY-RUN] Suppression simul√©e: {file_path}")
                return True
            else:
                os.remove(file_path)
                return True
        except Exception as e:
            logger.error(f"Erreur suppression {file_path}: {e}")
            return False
    
    def _get_container_ip(self, container_name: str) -> Optional[str]:
        """R√©cup√®re l'IP d'un conteneur Docker"""
        try:
            cmd = f"docker inspect {container_name} --format='{{{{.NetworkSettings.Networks.traefik_proxy.IPAddress}}}}'"
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=10)
            if result.returncode == 0 and result.stdout.strip():
                return result.stdout.strip()
        except Exception as e:
            logger.error(f"Erreur IP container {container_name}: {e}")
        return None
    
    def _get_api_key(self, service: str) -> Optional[str]:
        """R√©cup√®re la cl√© API d'un service"""
        try:
            settings_storage = os.environ.get('SETTINGS_STORAGE', '/opt/seedbox/docker')
            config_path = f"{settings_storage}/docker/{CURRENT_USER}/{service}/config/config.xml"
            
            if not os.path.exists(config_path):
                return None
                
            cmd = f"sed -n 's/.*<ApiKey>\\(.*\\)<\\/ApiKey>.*/\\1/p' '{config_path}'"
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
            return result.stdout.strip() if result.returncode == 0 else None
            
        except Exception as e:
            logger.error(f"Erreur API key {service}: {e}")
            return None
    
    def _trigger_media_rescan(self) -> bool:
        """D√©clenche les scans Sonarr/Radarr"""
        logger.info("üîÑ D√©clenchement scans Sonarr/Radarr")
        
        success = True
        
        for service, config in self.media_config.items():
            try:
                ip = self._get_container_ip(service)
                api_key = self._get_api_key(service)
                
                if not ip or not api_key:
                    logger.warning(f"‚ö†Ô∏è {service}: IP ou API key manquante")
                    continue
                
                url = f"http://{ip}:{config['port']}/api/{config['api_version']}/command"
                headers = {"Content-Type": "application/json", "X-Api-Key": api_key}
                
                # Commandes de scan selon le service
                commands = {
                    'sonarr': ['RescanSeries', 'missingEpisodeSearch'],
                    'radarr': ['RescanMovie', 'MissingMoviesSearch']
                }
                
                for command in commands.get(service, []):
                    data = {"name": command}
                    
                    if self.dry_run:
                        logger.info(f"[DRY-RUN] {service}: {command} simul√©")
                    else:
                        response = self.session.post(url, json=data, headers=headers, timeout=30)
                        response.raise_for_status()
                        logger.info(f"‚úÖ {service}: {command} lanc√©")
                    
                    time.sleep(2)
                    
            except Exception as e:
                logger.error(f"‚ùå {service} scan: {e}")
                success = False
        
        return success
    
    def _record_permanent_failure(self, torrent_id: str, filename: str, error_type: str, error_message: str):
        """Enregistre un √©chec permanent en base"""
        try:
            with self.database.get_cursor() as cursor:
                cursor.execute("""
                    INSERT OR REPLACE INTO permanent_failures (
                        torrent_id, filename, error_type, error_message, 
                        failure_date, processed
                    ) VALUES (?, ?, ?, ?, ?, ?)
                """, (torrent_id, filename, error_type, error_message, datetime.now(), True))
                
                logger.debug(f"√âchec permanent enregistr√©: {torrent_id}")
                
        except Exception as e:
            logger.error(f"Erreur enregistrement √©chec permanent: {e}")
    
    def _schedule_retry(self, torrent_id: str, filename: str, error_type: str, retry_time: datetime, error_message: str):
        """Programme un retry diff√©r√©"""
        try:
            with self.database.get_cursor() as cursor:
                cursor.execute("""
                    INSERT OR REPLACE INTO retry_queue (
                        torrent_id, filename, error_type, error_message,
                        original_failure, scheduled_retry, retry_count
                    ) VALUES (?, ?, ?, ?, ?, ?, ?)
                """, (torrent_id, filename, error_type, error_message, 
                     datetime.now(), retry_time, 0))
                
                logger.debug(f"Retry programm√©: {torrent_id} pour {retry_time}")
                
        except Exception as e:
            logger.error(f"Erreur programmation retry: {e}")
    
    def get_pending_retries(self) -> List[Dict]:
        """R√©cup√®re les torrents pr√™ts pour retry"""
        try:
            with self.database.get_cursor() as cursor:
                cursor.execute("""
                    SELECT * FROM retry_queue 
                    WHERE scheduled_retry <= ? 
                    AND retry_count < 3
                    ORDER BY scheduled_retry ASC
                """, (datetime.now(),))
                
                return [dict(row) for row in cursor.fetchall()]
                
        except Exception as e:
            logger.error(f"Erreur r√©cup√©ration retries: {e}")
            return []
    
    def close(self):
        """Fermeture propre"""
        if hasattr(self, 'session'):
            self.session.close()